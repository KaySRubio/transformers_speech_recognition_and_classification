{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbf9948-0a42-4c53-b926-4d7cbeb42ace",
   "metadata": {},
   "source": [
    "# Accent Classification Project: Data Prep Part 2\n",
    "This file is 1 of 3 in an Accent Classification Project\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "The goal of this project is to create an accent classifier for people who learned English as a second language by fine-tuning a speech recognition model to classify accents from 24 people speaking English whose first language is Hindi, Korean, Arabic, Vietnamese, Spanish, or Mandarin.\n",
    "\n",
    "**Data source**\n",
    "https://psi.engr.tamu.edu/l2-arctic-corpus/\n",
    "\n",
    "L2-Arctic dataset comes via email and includes approximately 24-30 hours of recordings where 24 speakers read passages in English. The first languages of the speakers are Arabic, Hindi, Korean, Mandarin, Spanish, and Vietnamese.  There's 2 women and 2 men in each language group.\n",
    "\n",
    "The original dataset is around 8GB with contains 27,000 rows of data, each with an audio file of 3-4s with 48k Hz sampling rate.\n",
    "\n",
    "**Summary of this file**\n",
    "This file merges the reformatted L2-Arctic Hugging Face datasets from Data Prep Part 1 into 1 big dataset. It then updates the labels to numeric and handles padding/attention mask for distilHuBERT model using its AutoFeatureExtractor.\n",
    "\n",
    "**Result**\n",
    "The final dataset has 1737 rows, each with a ~30s audio file at 16,000 Hz and is ready for training distilHuBERT\n",
    "\n",
    "**Environment**\n",
    "It runs best on a mac CPU, which is faster than google colab's CPU or GPU.\n",
    "Note: even when code is re-written to process files in bulk with GPU, a mac CPU is still surprisingly much faster. Splitting the dataset into smaller pieces then re-merging gets around the memory problems.\n",
    "\n",
    "**Data source**\n",
    "\n",
    "The [L2-Arctic](https://psi.engr.tamu.edu/l2-arctic-corpus/) data is ~8GB and comes via email. It includes approximately 24-30 hours of recordings where 24 speakers read passages in English. The first languages of the speakers are Arabic, Hindi, Korean, Mandarin, Spanish, and Vietnamese.  There's 2 women and 2 men in each language group.\n",
    "\n",
    "**Foundation Model**\n",
    "\n",
    "[DistilHuBERT](https://huggingface.co/ntu-spml/distilhubert) is a smaller version of HuBERT that was modified from BERT. BERT is a speech recognition model with encoder-only CTC architecture.  For this project, a classification layer was added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb25ca9-b451-41e4-9bee-42fdb86b4670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData\u001b[m\u001b[m         \u001b[34mLaCie\u001b[m\u001b[m        \u001b[35mMacintosh HD\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Check to make sure Jupyter Notebook can access my external drive where the data is saved\n",
    "!ls /Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac7aa756-6b7d-4047-ba0a-661f44a847ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dontfreakout/.pyenv/versions/3.12.8/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffce5c1-5635-4726-8136-d4d13d2b233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parent directory\n",
    "parent_dir = \"/Volumes/LaCie/l2-arctic-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717cb3f-f6e4-4b68-9d9c-eb52613f6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the individual Hugging Face datasets created in part 1 of data preparation\n",
    "arabic_data = load_from_disk(parent_dir+\"Arabic\")\n",
    "mandarin_data = load_from_disk(parent_dir+\"Mandarin\")\n",
    "hindi_data = load_from_disk(parent_dir+\"Hindi\")\n",
    "korean_data = load_from_disk(parent_dir+\"Korean\")\n",
    "spanish_data = load_from_disk(parent_dir+\"Spanish\")\n",
    "vietnamese_data = load_from_disk(parent_dir+\"Vietnamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdfa41b-f5b4-42c1-90bf-f038730b20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check datasets\n",
    "# arabic_data\n",
    "# len(arabic_data[0]['audio'])\n",
    "# mandarin_data\n",
    "# hindi_data\n",
    "# korean_data\n",
    "# spanish_data\n",
    "# vietnamese_data\n",
    "# len(vietnamese_data[len(vietnamese_data)-1]['audio'])\n",
    "# vietnamese_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c7f28ce-eccf-49d8-9de2-559f3808f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'audio'],\n",
      "    num_rows: 1737\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# stack datasets\n",
    "from datasets import concatenate_datasets\n",
    "data = concatenate_datasets([arabic_data, mandarin_data, hindi_data, korean_data, spanish_data, vietnamese_data])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4aa7a8",
   "metadata": {},
   "source": [
    "## Update labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b6fbc-1b2e-41cb-8c18-0effc57a06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this column from string to numeric but with labels\n",
    "data = data.class_encode_column('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca9cc62-fc0f-47ce-b54b-f0612834ec5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use method to map labels feature to human-readable names\n",
    "id2label_fn = data.features[\"label\"].int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf955f3-d504-47f3-ad9b-66da804d1903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check label now, should be numeric\n",
    "data[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66a63d7-f3fc-4405-9387-fd5fa7118120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arabic'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check label on one of the rows\n",
    "id2label_fn(data[0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e323c7d-8b85-49e2-9a1d-d0bfb0756fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of each label\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8b395-fee2-4b96-883e-258682229eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset):\n",
    "  label_counts = Counter(dataset[\"label\"]) \n",
    "  for label, count in sorted(label_counts.items()):\n",
    "    #print(f\"Label {label}: {count} occurrences\")\n",
    "    print(f\"Label {id2label_fn(label)}: {count} occurrences\")\n",
    "  print('length of dataset: ' + str(len(dataset)))\n",
    "  print('number of labeled rows (should match length of dataset): ' + str(sum(label_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b5e34-8408-4aa4-b6e0-6e05a479e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2aa6e",
   "metadata": {},
   "source": [
    "## Use AutoFeatureExtractor from model to prepare dataset with truncation/attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4abc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the AutoFeatureExtractor for DistilHuBERT so we can format data in\n",
    "# way that model expects\n",
    "from transformers import AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6011382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose pretrained model DistilHuBERT which is a smaller version of HuBERT\n",
    "# Alternatively could try full HuBERT or Wav2Vec2 but these will take longer to train\n",
    "# HuBERT and Wav2Vec2 models take in raw audio, not spectrograms\n",
    "# https://huggingface.co/ntu-spml/distilhubert\n",
    "model_id = \"ntu-spml/distilhubert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48522e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilHuBERT expects audio clips to be exactly 30 seconds\n",
    "MAX_DURATION = 30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65be166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to apply the feature_extractor to all the data\n",
    "def preprocess_function(examples):\n",
    "    # This is getting all raw signals in an array. So for each audio in the array passed to the function,\n",
    "    # take the audio column, then the array column, isolate those and put them in their own array\n",
    "    audio_arrays = [x for x in examples[\"audio\"]]\n",
    "    # Now apply the feature_extractor to all the audio arrays, and tell it the SR matches what\n",
    "    # it expects\n",
    "    # max_length in samples\n",
    "    # tell it to use truncation and return attention mask\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=int(feature_extractor.sampling_rate * MAX_DURATION),\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550df348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to truncate/pad the audio to the dataset using map\n",
    "data_encoded = data.map(\n",
    "    preprocess_function, # pass the preprocess_function defined above\n",
    "    batched=False,\n",
    "    num_proc=1,\n",
    ")\n",
    "data_encoded\n",
    "# - attention mask has a binary mask of 0/1 values that inducate where the audio input has been padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae9d26f",
   "metadata": {},
   "source": [
    "## Save data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47f7d7f-fbdd-436d-ad3d-9b7b471d821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (7/7 shards): 100%|â–ˆ| 1737/1737 [01:50<00:00, 15.75 examples/\n"
     ]
    }
   ],
   "source": [
    "# save hugging face dataset back to disk\n",
    "data.save_to_disk(\"/Volumes/LaCie/l2-arctic-data/arctic_data_formatted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
